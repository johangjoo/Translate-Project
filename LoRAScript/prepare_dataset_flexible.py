"""
JSON ë°ì´í„°ë¥¼ LoRA í•™ìŠµìš© ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜
í´ë” êµ¬ì¡° ììœ  ë²„ì „ - json_data í´ë” ì „ì²´ë¥¼ ì¬ê·€ íƒìƒ‰í•˜ì—¬
origin_langê³¼ tl_trans_lang í•„ë“œë¡œ ìë™ ë°©í–¥ íŒë‹¨
"""
import json
from pathlib import Path
from typing import Dict
from tqdm import tqdm

# ê²½ë¡œ ì„¤ì •
SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent
INPUT_DIR = PROJECT_ROOT / "json_data"  # json_data í´ë” ì „ì²´ íƒìƒ‰
OUTPUT_FILE = PROJECT_ROOT / "training_data.jsonl"

def create_translation_prompt(data: Dict) -> Dict:
    """
    JSON ë°ì´í„°ì—ì„œ í•™ìŠµìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
    origin_langê³¼ tl_trans_langìœ¼ë¡œ ìë™ ë°©í–¥ íŒë‹¨
    """
    # í™”ì ì •ë³´ ì¶”ì¶œ
    gender = data.get("speaker_gender", "unknown")
    age_group = data.get("speaker_age_group", "unknown")
    
    # ì›ë¬¸ê³¼ ë²ˆì—­ë¬¸
    source_text = data.get("tc_text", "").strip()
    target_text = data.get("tl_trans_text", "").strip()
    
    # ë°©í–¥ í™•ì¸ (JSON í•„ë“œë¡œ ìë™ íŒë‹¨!)
    origin_lang = data.get("origin_lang", "")
    trans_lang = data.get("tl_trans_lang", "")
    
    # ë¹ˆ ë°ì´í„° ìŠ¤í‚µ
    if not source_text or not target_text:
        return None
    
    # ì˜ì–´ í”„ë¡¬í”„íŠ¸ (ë°©í–¥ ìë™ íŒë‹¨)
    if "í•œêµ­ì–´" in origin_lang and "ì¼ë³¸ì–´" in trans_lang:
        # í•œêµ­ì–´ â†’ ì¼ë³¸ì–´
        instruction = f"""Translate the following Korean to Japanese naturally.
Speaker: {gender}, {age_group}

Korean: {source_text}"""
        response = target_text
        
    elif "ì¼ë³¸ì–´" in origin_lang and "í•œêµ­ì–´" in trans_lang:
        # ì¼ë³¸ì–´ â†’ í•œêµ­ì–´
        instruction = f"""Translate the following Japanese to Korean naturally.
Speaker: {gender}, {age_group}

Japanese: {source_text}"""
        response = target_text
    else:
        # ì§€ì›í•˜ì§€ ì•ŠëŠ” ì–¸ì–´ ìŒ
        return None
    
    return {
        "instruction": instruction,
        "input": "",
        "output": response
    }

def process_all_json_files(input_dir: Path, output_file: Path):
    """
    json_data í´ë” ì „ì²´ë¥¼ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰í•˜ì—¬ ëª¨ë“  JSON íŒŒì¼ ì²˜ë¦¬
    í´ë” êµ¬ì¡°ì— ìƒê´€ì—†ì´ JSON íŒŒì¼ë§Œ ì°¾ì•„ì„œ ì²˜ë¦¬
    """
    if not input_dir.exists():
        print(f"âŒ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
        print(f"   í”„ë¡œì íŠ¸ êµ¬ì¡°: Translate-Project/json_data/...")
        return
    
    # ëª¨ë“  JSON íŒŒì¼ ì°¾ê¸° (ì¬ê·€ì ìœ¼ë¡œ)
    json_files = list(input_dir.rglob("*.json"))
    
    if len(json_files) == 0:
        print(f"âŒ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
        return
    
    print(f"ğŸ“ JSON íŒŒì¼ ë°œê²¬: {len(json_files)}ê°œ")
    print(f"   ìœ„ì¹˜: {input_dir}\n")
    
    training_samples = []
    skipped = 0
    direction_stats = {
        'ko_to_ja': 0,  # í•œêµ­ì–´ â†’ ì¼ë³¸ì–´
        'ja_to_ko': 0,  # ì¼ë³¸ì–´ â†’ í•œêµ­ì–´
        'unknown': 0     # ë°©í–¥ ë¯¸ìƒ
    }
    
    # ëª¨ë“  JSON íŒŒì¼ ì²˜ë¦¬
    for json_file in tqdm(json_files, desc="JSON ì²˜ë¦¬ ì¤‘"):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # ë°©í–¥ íŒë‹¨ì„ ìœ„í•œ ì •ë³´ ì¶”ì¶œ
            origin_lang = data.get("origin_lang", "")
            trans_lang = data.get("tl_trans_lang", "")
            
            sample = create_translation_prompt(data)
            if sample:
                training_samples.append(sample)
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                if "í•œêµ­ì–´" in origin_lang and "ì¼ë³¸ì–´" in trans_lang:
                    direction_stats['ko_to_ja'] += 1
                elif "ì¼ë³¸ì–´" in origin_lang and "í•œêµ­ì–´" in trans_lang:
                    direction_stats['ja_to_ko'] += 1
                else:
                    direction_stats['unknown'] += 1
            else:
                skipped += 1
                
        except Exception as e:
            print(f"âš ï¸  {json_file.name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            skipped += 1
    
    # JSONL ì €ì¥
    output_file.parent.mkdir(parents=True, exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        for sample in training_samples:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    
    print(f"\n{'='*60}")
    print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"{'='*60}")
    print(f"ğŸ“Š ë°©í–¥ë³„ í†µê³„:")
    print(f"   - í•œêµ­ì–´â†’ì¼ë³¸ì–´: {direction_stats['ko_to_ja']}ê°œ")
    print(f"   - ì¼ë³¸ì–´â†’í•œêµ­ì–´: {direction_stats['ja_to_ko']}ê°œ")
    print(f"   - ë¯¸ìƒ/ê¸°íƒ€: {direction_stats['unknown']}ê°œ")
    print(f"   - ì´ ì„±ê³µ: {len(training_samples)}ê°œ")
    print(f"   - ì´ ìŠ¤í‚µ: {skipped}ê°œ")
    print(f"   - ì €ì¥ ìœ„ì¹˜: {output_file}")
    print(f"{'='*60}")

def split_train_val(input_file: Path, train_ratio: float = 0.95):
    """
    í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„ë¦¬ (95:5)
    """
    with open(input_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    total = len(lines)
    train_size = int(total * train_ratio)
    
    train_file = input_file.parent / "train.jsonl"
    val_file = input_file.parent / "validation.jsonl"
    
    with open(train_file, 'w', encoding='utf-8') as f:
        f.writelines(lines[:train_size])
    
    with open(val_file, 'w', encoding='utf-8') as f:
        f.writelines(lines[train_size:])
    
    print(f"\nğŸ“Š ë°ì´í„° ë¶„ë¦¬ ì™„ë£Œ:")
    print(f"   - í•™ìŠµ: {train_size}ê°œ â†’ {train_file}")
    print(f"   - ê²€ì¦: {total - train_size}ê°œ â†’ {val_file}")

if __name__ == "__main__":
    print("\n" + "="*60)
    print("  JSON â†’ í•™ìŠµ ë°ì´í„° ë³€í™˜ (í´ë” êµ¬ì¡° ììœ  ë²„ì „)")
    print("="*60 + "\n")
    
    print("ğŸ“‚ í´ë” êµ¬ì¡°:")
    print(f"   - íƒìƒ‰ ê²½ë¡œ: {INPUT_DIR}")
    print(f"   - ì¡´ì¬ ì—¬ë¶€: {'âœ…' if INPUT_DIR.exists() else 'âŒ'}")
    if INPUT_DIR.exists():
        # í•˜ìœ„ í´ë” ë¯¸ë¦¬ë³´ê¸°
        subdirs = [d.name for d in INPUT_DIR.iterdir() if d.is_dir()]
        if subdirs:
            print(f"   - í•˜ìœ„ í´ë”: {', '.join(subdirs[:5])}")
            if len(subdirs) > 5:
                print(f"     ... ì™¸ {len(subdirs)-5}ê°œ")
    print()
    
    # 1. JSON â†’ JSONL ë³€í™˜
    process_all_json_files(INPUT_DIR, OUTPUT_FILE)
    
    # 2. í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬
    if OUTPUT_FILE.exists():
        print()
        split_train_val(OUTPUT_FILE)
