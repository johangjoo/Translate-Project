# Qwen LoRA 학습 설정 파일

[model]
base_model = unsloth/Qwen3-8B
max_seq_length = 2048
load_in_4bit = True

[lora]
r = 16                    # LoRA rank (8~64)
alpha = 16                # 일반적으로 r과 동일
dropout = 0.05
target_modules = q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj

[training]
# 배치 설정 (12GB VRAM)
per_device_train_batch_size = 2
gradient_accumulation_steps = 4     # 실제 배치 = 2 * 4 = 8
per_device_eval_batch_size = 2

# 학습률
learning_rate = 2e-4
lr_scheduler_type = cosine
warmup_steps = 100

# 에폭
num_train_epochs = 3
max_steps = -1                      # -1이면 에폭 기준

# 평가 및 저장
eval_steps = 500
save_steps = 500
save_total_limit = 3
logging_steps = 50

# 최적화
optim = adamw_8bit
weight_decay = 0.01
max_grad_norm = 1.0

[generation]
max_new_tokens = 512
temperature = 0.7
top_p = 0.9
repetition_penalty = 1.1

# ===========================================
# 메모리 부족 시:
# ===========================================
# per_device_train_batch_size = 1
# gradient_accumulation_steps = 8
# r = 8
# max_seq_length = 1024

# ===========================================
# 더 나은 품질:
# ===========================================
# num_train_epochs = 5
# r = 32
# learning_rate = 1e-4
