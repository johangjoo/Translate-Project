"""
OpenAI API ë²ˆì—­ ëª¨ë¸ (ì• ë‹ˆ/ìœ íŠœë¸Œ ìŠ¤í¬ë¦½íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì§€ì› ë²„ì „)
"""

import logging
from typing import Optional, Dict, Tuple
import re

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

from .base import BaseTranslator, TranslationResult

logger = logging.getLogger(__name__)


class OpenAITranslator(BaseTranslator):
    """OpenAI API ê¸°ë°˜ ë²ˆì—­ ëª¨ë¸"""

    # ìë§‰ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° (ìœ„/ì•„ë˜ ëª‡ ì¤„ê¹Œì§€ ë³¼ì§€)
    CONTEXT_WINDOW_LINES = 2

    def __init__(self, api_key: str, model: str = "gpt-5.1"):
        """
        Args:
            api_key: OpenAI API í‚¤
            model: ì‚¬ìš©í•  ëª¨ë¸ (ì˜ˆ: gpt-5.1, gpt-4.1, gpt-4.1-mini ë“±)
        """
        super().__init__("openai")

        if not OPENAI_AVAILABLE:
            raise ImportError(
                "openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                "pip install openai ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
            )

        if not api_key:
            raise ValueError("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        self.api_key = api_key
        self.model = model
        self.client: Optional[OpenAI] = None

        logger.info(f"OpenAITranslator ì´ˆê¸°í™” - ëª¨ë¸: {self.model}")

    # ------------------------------------------------------------------
    # ì´ˆê¸°í™” / ì •ë¦¬
    # ------------------------------------------------------------------
    def load_model(self, **kwargs):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if self.client is not None:
            logger.warning("í´ë¼ì´ì–¸íŠ¸ê°€ ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            self._loaded = True
            return

        try:
            self.client = OpenAI(api_key=self.api_key)
            self._loaded = True
            logger.info("[OK] OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"[ERROR] OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    def unload_model(self):
        """í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬"""
        self.client = None
        self._loaded = False
        logger.info("OpenAI í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬ ì™„ë£Œ")

    # ------------------------------------------------------------------
    # ê³µê°œ API
    # ------------------------------------------------------------------
    def translate(
        self,
        text: str,
        source_lang: str = "ko",
        target_lang: str = "ja",
        temperature: float = 0.3,
        **kwargs
    ) -> TranslationResult:
        """í…ìŠ¤íŠ¸ ë²ˆì—­ (í˜•ì‹ ìë™ ê°ì§€)"""
        if self.client is None:
            raise RuntimeError("í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_model()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")

        # í˜•ì‹ ìë™ ê°ì§€ (BaseTranslator ìª½ì— ìˆë‹¤ê³  ê°€ì •)
        format_type = self._detect_format(text)

        if format_type == "transcript":
            logger.info("ğŸ“‹ ìë™ ê°ì§€: íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ í˜•ì‹")
            result = self._translate_transcript(text, source_lang, target_lang, temperature)
        elif format_type == "multiline":
            logger.info("ğŸ“ ìë™ ê°ì§€: ì—¬ëŸ¬ ì¤„ í…ìŠ¤íŠ¸")
            result = self._translate_multiline(text, source_lang, target_lang, temperature)
        else:
            logger.info("ğŸ’¬ ìë™ ê°ì§€: ì¼ë°˜ í…ìŠ¤íŠ¸")
            result = self._translate_single(text, source_lang, target_lang, temperature)

        return result

    # ------------------------------------------------------------------
    # ë‚´ë¶€ í—¬í¼: ê³µí†µ í”„ë¡¬í”„íŠ¸/í˜¸ì¶œ
    # ------------------------------------------------------------------
    @staticmethod
    def _get_lang_name(lang_code: str) -> str:
        lang_map = {
            "ko": "Korean",
            "ja": "Japanese",
            "en": "English",
        }
        return lang_map.get(lang_code.lower(), lang_code)

    def _build_system_prompt_basic(self, source_full: str, target_full: str) -> str:
        """ì¼ë°˜ ë‹¨ì¼ ë¬¸ì¥/ë¬¸ë‹¨ ë²ˆì—­ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return (
            f"You are a professional translator specializing in {source_full} to {target_full} translation. "
            "Translate ONLY the given text accurately without any explanations, notes, or additional content. "
            "Do not mix other languages. Output only the translated text."
        )

    def _build_system_prompt_subtitle(self, source_full: str, target_full: str) -> str:
        """ì• ë‹ˆ/ì˜ìƒ ìë§‰ ë²ˆì—­ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì „ì²´ í…ìŠ¤íŠ¸ ë²ˆì—­)"""
        return f"""
You are a professional subtitle translator specializing in {source_full} â†’ {target_full}.
You mainly translate anime, movies, dramas, games, and YouTube videos.

General rules:
- Translate the ENTIRE text while maintaining the original line structure.
- Understand the full context to ensure consistent translation of characters, relationships, and running themes.
- Maintain the exact number of lines: 1 input line MUST correspond to 1 output line. Do not merge or split lines.
- Keep the translation concise and readable as on-screen subtitles.
- Preserve speaker names, timecodes, brackets, emoji, and sound effects when meaningful.
- Preserve honorifics or speech level implied in the source (polite, casual, rude, etc.)
- Ensure consistency in character names, pronouns, and terminology throughout the entire text.
- Do NOT add any explanations, notes, or commentary.
- Output ONLY the translated text in {target_full}, maintaining the same line structure as the input.
""".strip()

    def _build_user_prompt_basic(
        self,
        text: str,
        source_full: str,
        target_full: str,
    ) -> str:
        """ì¼ë°˜ ë²ˆì—­ìš© ìœ ì € í”„ë¡¬í”„íŠ¸"""
        return (
            f"Translate the following text from {source_full} to {target_full}:\n\n{text}"
        )

    def _build_user_prompt_full_text(
        self,
        source_full: str,
        target_full: str,
        full_text: str,
    ) -> str:
        """ì „ì²´ í…ìŠ¤íŠ¸ ë²ˆì—­ìš© ìœ ì € í”„ë¡¬í”„íŠ¸"""
        return f"""
[SOURCE_LANGUAGE]: {source_full}
[TARGET_LANGUAGE]: {target_full}

[FULL_TEXT_TO_TRANSLATE]
{full_text}

Task:
Translate the entire text above from {source_full} to {target_full}.
Maintain the exact line structure - each line should be translated separately but with full context awareness.
Return ONLY the translated text, preserving the same number of lines and structure.
""".strip()

    def _call_openai(
        self,
        system_prompt: str,
        user_prompt: str,
        temperature: float,
        max_output_tokens: int = 512,
    ) -> Tuple[str, int, int]:
        """Responses API ê³µí†µ í˜¸ì¶œ ë¶€ë¶„"""
        try:
            response = self.client.responses.create(
                model=self.model,
                input=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=temperature,
                max_output_tokens=max_output_tokens,
            )

            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            translated_text = getattr(response, "output_text", None)
            if not translated_text:
                # ì•ˆì „í•˜ê²Œ fallback
                translated_text = (
                    response.output[0].content[0].text.strip()
                    if response.output and response.output[0].content
                    else ""
                )
            translated_text = translated_text.strip()

            # í† í° ì‚¬ìš©ëŸ‰
            usage = getattr(response, "usage", None)
            input_tokens = getattr(usage, "input_tokens", 0) if usage else 0
            output_tokens = getattr(usage, "output_tokens", 0) if usage else 0

            return translated_text, input_tokens, output_tokens

        except Exception as e:
            logger.error(f"[ERROR] OpenAI ë²ˆì—­ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise

    # ------------------------------------------------------------------
    # ë‹¨ì¼ í…ìŠ¤íŠ¸ ë²ˆì—­ (ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ)
    # ------------------------------------------------------------------
    def _translate_single(
        self,
        text: str,
        source_lang: str,
        target_lang: str,
        temperature: float,
    ) -> TranslationResult:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ë²ˆì—­ (ìë§‰ ì»¨í…ìŠ¤íŠ¸ X)"""
        logger.info(f"ë²ˆì—­ ì‹œì‘ (ë‹¨ì¼): {source_lang} â†’ {target_lang}")

        source_full = self._get_lang_name(source_lang)
        target_full = self._get_lang_name(target_lang)

        system_prompt = self._build_system_prompt_basic(source_full, target_full)
        user_prompt = self._build_user_prompt_basic(text, source_full, target_full)

        translated_text, input_tokens, output_tokens = self._call_openai(
            system_prompt, user_prompt, temperature, max_output_tokens=4096
        )

        logger.info(f"[OK] ë²ˆì—­ ì™„ë£Œ: {len(translated_text)} ê¸€ì")

        return TranslationResult(
            original_text=text,
            translated_text=translated_text,
            source_lang=source_lang,
            target_lang=target_lang,
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            model_name=f"{self.model_name}:{self.model}",
        )

    # ------------------------------------------------------------------
    # ì—¬ëŸ¬ ì¤„ í…ìŠ¤íŠ¸ ë²ˆì—­ (ìë§‰ ì»¨í…ìŠ¤íŠ¸ ON)
    # ------------------------------------------------------------------
    def _translate_multiline(
        self,
        text: str,
        source_lang: str,
        target_lang: str,
        temperature: float,
    ) -> TranslationResult:
        """ì—¬ëŸ¬ ì¤„ í…ìŠ¤íŠ¸ ë²ˆì—­ (ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ë²ˆì—­í•˜ì—¬ ë¬¸ë§¥ íŒŒì•…)"""
        source_full = self._get_lang_name(source_lang)
        target_full = self._get_lang_name(target_lang)

        lines = text.strip().split("\n")
        logger.info(f"ì „ì²´ í…ìŠ¤íŠ¸ ë²ˆì—­: {len(lines)}ì¤„")

        system_prompt = self._build_system_prompt_subtitle(source_full, target_full)
        user_prompt = self._build_user_prompt_full_text(
            source_full,
            target_full,
            text,
        )

        # ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ë²ˆì—­
        translated_text, input_tokens, output_tokens = self._call_openai(
            system_prompt, user_prompt, temperature, max_output_tokens=4096
        )

        # ì¤„ ìˆ˜ê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì¡°ì •
        translated_lines = translated_text.strip().split("\n")
        original_lines = text.strip().split("\n")
        
        # ì¤„ ìˆ˜ê°€ ë‹¤ë¥´ë©´ ê²½ê³ 
        if len(translated_lines) != len(original_lines):
            logger.warning(
                f"ë²ˆì—­ëœ ì¤„ ìˆ˜({len(translated_lines)})ê°€ ì›ë³¸ ì¤„ ìˆ˜({len(original_lines)})ì™€ ë‹¤ë¦…ë‹ˆë‹¤. "
                "ì›ë³¸ ì¤„ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë„ë¡ ì¡°ì •í•©ë‹ˆë‹¤."
            )
            # ì›ë³¸ ì¤„ ìˆ˜ì— ë§ì¶° ì¡°ì •
            if len(translated_lines) < len(original_lines):
                # ë¶€ì¡±í•œ ì¤„ì€ ë¹ˆ ì¤„ë¡œ ì±„ì›€
                translated_lines.extend([""] * (len(original_lines) - len(translated_lines)))
            else:
                # ì´ˆê³¼í•œ ì¤„ì€ ë³‘í•©
                translated_lines = translated_lines[:len(original_lines)]

        logger.info(f"[OK] ì „ì²´ í…ìŠ¤íŠ¸ ë²ˆì—­ ì™„ë£Œ: {len(original_lines)}ì¤„")

        return TranslationResult(
            original_text=text,
            translated_text="\n".join(translated_lines),
            source_lang=source_lang,
            target_lang=target_lang,
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            model_name=f"{self.model_name}:{self.model}",
        )

    # ------------------------------------------------------------------
    # íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë²ˆì—­ (íƒ€ì„ìŠ¤íƒ¬í”„/í™”ì ìœ ì§€ + ì»¨í…ìŠ¤íŠ¸)
    # ------------------------------------------------------------------
    def _translate_transcript(
        self,
        text: str,
        source_lang: str,
        target_lang: str,
        temperature: float,
    ) -> TranslationResult:
        """íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë²ˆì—­: [íƒ€ì„ìŠ¤íƒ¬í”„] í™”ì: ë‚´ìš©  í˜•ì‹ì„ ìœ ì§€í•˜ë©´ì„œ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ë²ˆì—­"""
        lines = text.strip().split("\n")
        # [íƒ€ì„ìŠ¤íƒ¬í”„] Speaker: ë‚´ìš©
        pattern = r'^(\[[\d:\.]+\])?\s*(í™”ì\d+|Speaker\d+|[^:]+):\s*(.+)$'

        source_full = self._get_lang_name(source_lang)
        target_full = self._get_lang_name(target_lang)

        logger.info(f"íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì „ì²´ ë²ˆì—­: {len(lines)}ì¤„")

        # íƒ€ì„ìŠ¤íƒ¬í”„ì™€ í™”ì ì •ë³´ ì¶”ì¶œ
        transcript_parts = []
        for line in lines:
            if not line.strip():
                transcript_parts.append(("", "", ""))
                continue
            
            match = re.match(pattern, line)
            if match:
                timestamp = match.group(1) or ""
                speaker = match.group(2)
                content = match.group(3).strip()
                transcript_parts.append((timestamp, speaker, content))
            else:
                # íŒ¨í„´ ë¶ˆì¼ì¹˜: ì „ì²´ë¥¼ ë‚´ìš©ìœ¼ë¡œ ì·¨ê¸‰
                transcript_parts.append(("", "", line.strip()))

        # ë‚´ìš©ë§Œ ì¶”ì¶œí•˜ì—¬ ë²ˆì—­
        content_lines = []
        for timestamp, speaker, content in transcript_parts:
            if timestamp and speaker:
                content_lines.append(content)
            elif content:
                content_lines.append(content)
            else:
                content_lines.append("")

        content_text = "\n".join(content_lines)

        # ì „ì²´ ë‚´ìš©ì„ í•œ ë²ˆì— ë²ˆì—­
        system_prompt = self._build_system_prompt_subtitle(source_full, target_full)
        user_prompt = self._build_user_prompt_full_text(
            source_full,
            target_full,
            content_text,
        )

        try:
            translated_content, input_tokens, output_tokens = self._call_openai(
                system_prompt, user_prompt, temperature, max_output_tokens=4096
            )

            # ë²ˆì—­ëœ ë‚´ìš©ì„ ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
            translated_content_lines = translated_content.strip().split("\n")
            
            # ì›ë³¸ êµ¬ì¡°ì— ë§ì¶° ì¬ì¡°ë¦½
            translated_lines = []
            for idx, (timestamp, speaker, _) in enumerate(transcript_parts):
                if not timestamp and not speaker and not transcript_parts[idx][2]:
                    # ë¹ˆ ì¤„
                    translated_lines.append("")
                elif idx < len(translated_content_lines):
                    translated_text = translated_content_lines[idx].strip()
                    if timestamp and speaker:
                        reconstructed = f"{timestamp} {speaker}: {translated_text}"
                    elif speaker:
                        reconstructed = f"{speaker}: {translated_text}"
                    else:
                        reconstructed = translated_text
                    translated_lines.append(reconstructed)
                else:
                    # ë²ˆì—­ ê²°ê³¼ê°€ ë¶€ì¡±í•œ ê²½ìš°
                    logger.warning(f"  {idx + 1}ë²ˆì§¸ ì¤„: ë²ˆì—­ ê²°ê³¼ ë¶€ì¡±")
                    translated_lines.append(f"[ë²ˆì—­ ì‹¤íŒ¨] {lines[idx]}")

            logger.info(f"[OK] íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë²ˆì—­ ì™„ë£Œ: {len(lines)}ì¤„")

            return TranslationResult(
                original_text=text,
                translated_text="\n".join(translated_lines),
                source_lang=source_lang,
                target_lang=target_lang,
                input_tokens=input_tokens,
                output_tokens=output_tokens,
                model_name=f"{self.model_name}:{self.model}",
            )

        except Exception as e:
            logger.error(f"[ERROR] íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë²ˆì—­ ì‹¤íŒ¨: {e}")
            raise
