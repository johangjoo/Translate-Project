"""
OpenAI API ë²ˆì—­ ëª¨ë¸ (ì• ë‹ˆ/ìœ íŠœë¸Œ ìŠ¤í¬ë¦½íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì§€ì› ë²„ì „)
"""

import logging
from typing import Optional, Dict, Tuple
import re

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

from .base import BaseTranslator, TranslationResult

logger = logging.getLogger(__name__)


class OpenAITranslator(BaseTranslator):
    """OpenAI API ê¸°ë°˜ ë²ˆì—­ ëª¨ë¸"""

    # ìë§‰ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° (ìœ„/ì•„ë˜ ëª‡ ì¤„ê¹Œì§€ ë³¼ì§€)
    CONTEXT_WINDOW_LINES = 2

    def __init__(self, api_key: str, model: str = "gpt-5.1"):
        """
        Args:
            api_key: OpenAI API í‚¤
            model: ì‚¬ìš©í•  ëª¨ë¸ (ì˜ˆ: gpt-5.1, gpt-4.1, gpt-4.1-mini ë“±)
        """
        super().__init__("openai")

        if not OPENAI_AVAILABLE:
            raise ImportError(
                "openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                "pip install openai ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
            )

        if not api_key:
            raise ValueError("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        self.api_key = api_key
        self.model = model
        self.client: Optional[OpenAI] = None

        logger.info(f"OpenAITranslator ì´ˆê¸°í™” - ëª¨ë¸: {self.model}")

    # ------------------------------------------------------------------
    # ì´ˆê¸°í™” / ì •ë¦¬
    # ------------------------------------------------------------------
    def load_model(self, **kwargs):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if self.client is not None:
            logger.warning("í´ë¼ì´ì–¸íŠ¸ê°€ ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            self._loaded = True
            return

        try:
            self.client = OpenAI(api_key=self.api_key)
            self._loaded = True
            logger.info("[OK] OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"[ERROR] OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    def unload_model(self):
        """í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬"""
        self.client = None
        self._loaded = False
        logger.info("OpenAI í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬ ì™„ë£Œ")

    # ------------------------------------------------------------------
    # ê³µê°œ API
    # ------------------------------------------------------------------
    def translate(
        self,
        text: str,
        source_lang: str = "ko",
        target_lang: str = "ja",
        temperature: float = 0.3,
        **kwargs
    ) -> TranslationResult:
        """í…ìŠ¤íŠ¸ ë²ˆì—­ (í˜•ì‹ ìë™ ê°ì§€)"""
        if self.client is None:
            raise RuntimeError("í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_model()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")

        # í˜•ì‹ ìë™ ê°ì§€ (BaseTranslator ìª½ì— ìˆë‹¤ê³  ê°€ì •)
        format_type = self._detect_format(text)

        if format_type == "transcript":
            logger.info("ğŸ“‹ ìë™ ê°ì§€: íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ í˜•ì‹")
            result = self._translate_transcript(text, source_lang, target_lang, temperature)
        elif format_type == "multiline":
            logger.info("ğŸ“ ìë™ ê°ì§€: ì—¬ëŸ¬ ì¤„ í…ìŠ¤íŠ¸")
            result = self._translate_multiline(text, source_lang, target_lang, temperature)
        else:
            logger.info("ğŸ’¬ ìë™ ê°ì§€: ì¼ë°˜ í…ìŠ¤íŠ¸")
            result = self._translate_single(text, source_lang, target_lang, temperature)

        return result

    # ------------------------------------------------------------------
    # ë‚´ë¶€ í—¬í¼: ê³µí†µ í”„ë¡¬í”„íŠ¸/í˜¸ì¶œ
    # ------------------------------------------------------------------
    @staticmethod
    def _get_lang_name(lang_code: str) -> str:
        lang_map = {
            "ko": "Korean",
            "ja": "Japanese",
            "en": "English",
        }
        return lang_map.get(lang_code.lower(), lang_code)

    def _build_system_prompt_basic(self, source_full: str, target_full: str) -> str:
        """ì¼ë°˜ ë‹¨ì¼ ë¬¸ì¥/ë¬¸ë‹¨ ë²ˆì—­ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return (
            f"You are a professional translator specializing in {source_full} to {target_full} translation. "
            "Translate ONLY the given text accurately without any explanations, notes, or additional content. "
            "Do not mix other languages. Output only the translated text."
        )

    def _build_system_prompt_subtitle(self, source_full: str, target_full: str) -> str:
        """ì• ë‹ˆ/ì˜ìƒ ìë§‰ ë²ˆì—­ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return f"""
You are a professional subtitle translator specializing in {source_full} â†’ {target_full}.
You mainly translate anime, movies, dramas, games, and YouTube videos.

General rules:
- Translate ONLY the utterance marked [CURRENT_LINE].
- Use [PREVIOUS_LINES] and [NEXT_LINES] only to understand context
  (who is speaking, who pronouns refer to, running jokes, relationship, tone).
- 1 input line MUST correspond to 1 output line. Do not merge or split lines.
- Keep the translation concise and readable as on-screen subtitles.
- Preserve speaker names, timecodes, brackets, emoji, and sound effects when meaningful.
- Preserve honorifics or speech level implied in the source (polite, casual, rude, etc.)
- Do NOT add any explanations, notes, or commentary.
- Output ONLY the translated text for [CURRENT_LINE] in {target_full}.
""".strip()

    def _build_user_prompt_basic(
        self,
        text: str,
        source_full: str,
        target_full: str,
    ) -> str:
        """ì¼ë°˜ ë²ˆì—­ìš© ìœ ì € í”„ë¡¬í”„íŠ¸"""
        return (
            f"Translate the following text from {source_full} to {target_full}:\n\n{text}"
        )

    def _build_user_prompt_subtitle(
        self,
        source_full: str,
        target_full: str,
        previous_lines: str,
        current_line: str,
        next_lines: str,
    ) -> str:
        """ìë§‰ ì»¨í…ìŠ¤íŠ¸ìš© ìœ ì € í”„ë¡¬í”„íŠ¸"""
        prev_block = previous_lines.strip() if previous_lines.strip() else "(none)"
        next_block = next_lines.strip() if next_lines.strip() else "(none)"

        return f"""
[SOURCE_LANGUAGE]: {source_full}
[TARGET_LANGUAGE]: {target_full}

[PREVIOUS_LINES]
{prev_block}

[CURRENT_LINE]
{current_line}

[NEXT_LINES]
{next_block}

Task:
Translate [CURRENT_LINE] into {target_full} as a natural subtitle.
Return ONLY the translation of [CURRENT_LINE].
""".strip()

    def _call_openai(
        self,
        system_prompt: str,
        user_prompt: str,
        temperature: float,
        max_output_tokens: int = 512,
    ) -> Tuple[str, int, int]:
        """Responses API ê³µí†µ í˜¸ì¶œ ë¶€ë¶„"""
        try:
            response = self.client.responses.create(
                model=self.model,
                input=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=temperature,
                max_output_tokens=max_output_tokens,
            )

            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            translated_text = getattr(response, "output_text", None)
            if not translated_text:
                # ì•ˆì „í•˜ê²Œ fallback
                translated_text = (
                    response.output[0].content[0].text.strip()
                    if response.output and response.output[0].content
                    else ""
                )
            translated_text = translated_text.strip()

            # í† í° ì‚¬ìš©ëŸ‰
            usage = getattr(response, "usage", None)
            input_tokens = getattr(usage, "input_tokens", 0) if usage else 0
            output_tokens = getattr(usage, "output_tokens", 0) if usage else 0

            return translated_text, input_tokens, output_tokens

        except Exception as e:
            logger.error(f"[ERROR] OpenAI ë²ˆì—­ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise

    # ------------------------------------------------------------------
    # ë‹¨ì¼ í…ìŠ¤íŠ¸ ë²ˆì—­ (ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ)
    # ------------------------------------------------------------------
    def _translate_single(
        self,
        text: str,
        source_lang: str,
        target_lang: str,
        temperature: float,
    ) -> TranslationResult:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ë²ˆì—­ (ìë§‰ ì»¨í…ìŠ¤íŠ¸ X)"""
        logger.info(f"ë²ˆì—­ ì‹œì‘ (ë‹¨ì¼): {source_lang} â†’ {target_lang}")

        source_full = self._get_lang_name(source_lang)
        target_full = self._get_lang_name(target_lang)

        system_prompt = self._build_system_prompt_basic(source_full, target_full)
        user_prompt = self._build_user_prompt_basic(text, source_full, target_full)

        translated_text, input_tokens, output_tokens = self._call_openai(
            system_prompt, user_prompt, temperature, max_output_tokens=4096
        )

        logger.info(f"[OK] ë²ˆì—­ ì™„ë£Œ: {len(translated_text)} ê¸€ì")

        return TranslationResult(
            original_text=text,
            translated_text=translated_text,
            source_lang=source_lang,
            target_lang=target_lang,
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            model_name=f"{self.model_name}:{self.model}",
        )

    # ------------------------------------------------------------------
    # ì—¬ëŸ¬ ì¤„ í…ìŠ¤íŠ¸ ë²ˆì—­ (ìë§‰ ì»¨í…ìŠ¤íŠ¸ ON)
    # ------------------------------------------------------------------
    def _translate_multiline(
        self,
        text: str,
        source_lang: str,
        target_lang: str,
        temperature: float,
    ) -> TranslationResult:
        """ì—¬ëŸ¬ ì¤„ í…ìŠ¤íŠ¸ ë²ˆì—­ (ì• ë‹ˆ/ìœ íŠœë¸Œ ìŠ¤í¬ë¦½íŠ¸ ê°€ì •, ë¼ì¸ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©)"""
        lines = text.strip().split("\n")
        translated_lines = []
        total_input_tokens = 0
        total_output_tokens = 0

        source_full = self._get_lang_name(source_lang)
        target_full = self._get_lang_name(target_lang)

        logger.info(f"ì¤„ ë‹¨ìœ„ ë²ˆì—­ (ì»¨í…ìŠ¤íŠ¸): {len(lines)}ì¤„")

        for idx, line in enumerate(lines):
            current = line.strip()

            if not current:
                translated_lines.append("")
                continue

            # ìœ—/ì•„ë«ì¤„ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            start_idx = max(0, idx - self.CONTEXT_WINDOW_LINES)
            end_idx = min(len(lines), idx + self.CONTEXT_WINDOW_LINES + 1)

            previous_lines = "\n".join(lines[start_idx:idx])
            next_lines = "\n".join(lines[idx + 1:end_idx])

            system_prompt = self._build_system_prompt_subtitle(source_full, target_full)
            user_prompt = self._build_user_prompt_subtitle(
                source_full,
                target_full,
                previous_lines=previous_lines,
                current_line=current,
                next_lines=next_lines,
            )

            translated_text, in_tok, out_tok = self._call_openai(
                system_prompt, user_prompt, temperature, max_output_tokens=512
            )

            translated_lines.append(translated_text)
            total_input_tokens += in_tok
            total_output_tokens += out_tok

            logger.debug(f"  {idx + 1}/{len(lines)} ì¤„ ë³€ì—­ ì™„ë£Œ")

        logger.info(f"[OK] ì¤„ ë‹¨ìœ„ ë²ˆì—­ ì™„ë£Œ: {len(lines)}ì¤„")

        return TranslationResult(
            original_text=text,
            translated_text="\n".join(translated_lines),
            source_lang=source_lang,
            target_lang=target_lang,
            input_tokens=total_input_tokens,
            output_tokens=total_output_tokens,
            model_name=f"{self.model_name}:{self.model}",
        )

    # ------------------------------------------------------------------
    # íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë²ˆì—­ (íƒ€ì„ìŠ¤íƒ¬í”„/í™”ì ìœ ì§€ + ì»¨í…ìŠ¤íŠ¸)
    # ------------------------------------------------------------------
    def _translate_transcript(
        self,
        text: str,
        source_lang: str,
        target_lang: str,
        temperature: float,
    ) -> TranslationResult:
        """íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë²ˆì—­: [íƒ€ì„ìŠ¤íƒ¬í”„] í™”ì: ë‚´ìš©  í˜•ì‹ì„ ìœ ì§€í•˜ë©´ì„œ ë²ˆì—­"""
        lines = text.strip().split("\n")
        translated_lines = []
        total_input_tokens = 0
        total_output_tokens = 0

        # [íƒ€ì„ìŠ¤íƒ¬í”„] Speaker: ë‚´ìš©
        pattern = r'^(\[[\d:\.]+\])?\s*(í™”ì\d+|Speaker\d+|[^:]+):\s*(.+)$'

        source_full = self._get_lang_name(source_lang)
        target_full = self._get_lang_name(target_lang)

        logger.info(f"íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë²ˆì—­ (ì»¨í…ìŠ¤íŠ¸): {len(lines)}ì¤„")

        for idx, raw_line in enumerate(lines):
            line = raw_line.strip()

            if not line:
                translated_lines.append("")
                continue

            # ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ê³„ì‚°
            start_idx = max(0, idx - self.CONTEXT_WINDOW_LINES)
            end_idx = min(len(lines), idx + self.CONTEXT_WINDOW_LINES + 1)

            previous_lines = "\n".join(lines[start_idx:idx])
            next_lines = "\n".join(lines[idx + 1:end_idx])

            match = re.match(pattern, line)

            if match:
                timestamp = match.group(1) or ""
                speaker = match.group(2)
                content = match.group(3).strip()

                system_prompt = self._build_system_prompt_subtitle(source_full, target_full)
                user_prompt = self._build_user_prompt_subtitle(
                    source_full,
                    target_full,
                    previous_lines=previous_lines,
                    current_line=content,
                    next_lines=next_lines,
                )

                try:
                    translated_text, in_tok, out_tok = self._call_openai(
                        system_prompt, user_prompt, temperature, max_output_tokens=512
                    )

                    if timestamp:
                        reconstructed = f"{timestamp} {speaker}: {translated_text}"
                    else:
                        reconstructed = f"{speaker}: {translated_text}"

                    translated_lines.append(reconstructed)
                    total_input_tokens += in_tok
                    total_output_tokens += out_tok

                    logger.debug(f"  {idx + 1}/{len(lines)} [{speaker}] ë²ˆì—­ ì™„ë£Œ")

                except Exception as e:
                    logger.error(f"  {idx + 1}ë²ˆì§¸ ì¤„ ì‹¤íŒ¨: {e}")
                    translated_lines.append(f"[ë²ˆì—­ ì‹¤íŒ¨] {line}")
            else:
                # íŒ¨í„´ ë¶ˆì¼ì¹˜: ì¼ë°˜ ì¤„ë¡œ ì·¨ê¸‰
                system_prompt = self._build_system_prompt_subtitle(source_full, target_full)
                user_prompt = self._build_user_prompt_subtitle(
                    source_full,
                    target_full,
                    previous_lines=previous_lines,
                    current_line=line,
                    next_lines=next_lines,
                )

                try:
                    translated_text, in_tok, out_tok = self._call_openai(
                        system_prompt, user_prompt, temperature, max_output_tokens=512
                    )
                    translated_lines.append(translated_text)
                    total_input_tokens += in_tok
                    total_output_tokens += out_tok
                except Exception as e:
                    logger.error(f"  {idx + 1}ë²ˆì§¸ ì¤„ ì‹¤íŒ¨(íŒ¨í„´ ë¶ˆì¼ì¹˜): {e}")
                    translated_lines.append(f"[ë²ˆì—­ ì‹¤íŒ¨] {line}")

        logger.info(f"[OK] íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë²ˆì—­ ì™„ë£Œ: {len(lines)}ì¤„")

        return TranslationResult(
            original_text=text,
            translated_text="\n".join(translated_lines),
            source_lang=source_lang,
            target_lang=target_lang,
            input_tokens=total_input_tokens,
            output_tokens=total_output_tokens,
            model_name=f"{self.model_name}:{self.model}",
        )
