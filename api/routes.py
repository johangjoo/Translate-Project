"""
API ë¼ìš°íŠ¸ - ê°„ì†Œí™” ë²„ì „
- ì˜¤ë””ì˜¤ íŒŒì´í”„ë¼ì¸ (ë…¸ì´ì¦ˆ ì œê±° + STT + í™”ìë¶„ë¦¬)
- í…ìŠ¤íŠ¸ ë²ˆì—­
"""

from fastapi import APIRouter, UploadFile, File, HTTPException, Form
from pydantic import BaseModel, Field
from pathlib import Path
import os
import uuid
import shutil
import time
import re
from typing import Optional, List, Dict

# models.pyì—ì„œ import
from .models import (
    TranslationResponse,
    AudioProcessResponse,
    AudioHealthResponse
)

router = APIRouter()

# ì—…ë¡œë“œ ë””ë ‰í† ë¦¬
UPLOAD_DIR = Path("uploads")
UPLOAD_DIR.mkdir(exist_ok=True)


# ===== Pydantic ëª¨ë¸ (routes ì „ìš©) =====

class BasicHealthResponse(BaseModel):
    """ê¸°ë³¸ í—¬ìŠ¤ ì²´í¬ ì‘ë‹µ"""
    status: str
    stt_loaded: bool
    translator_loaded: bool
    stt_device: str
    translator_device: str


# ===== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ =====

def save_upload_file(upload_file: UploadFile, max_size_mb: int = 200) -> str:
    """ì—…ë¡œë“œ íŒŒì¼ ì €ì¥"""
    upload_file.file.seek(0, 2)
    file_size = upload_file.file.tell()
    upload_file.file.seek(0)
    
    max_size = max_size_mb * 1024 * 1024
    if file_size > max_size:
        raise HTTPException(
            status_code=413,
            detail=f"íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€: {max_size_mb}MB"
        )
    
    file_ext = os.path.splitext(upload_file.filename)[1]
    if not file_ext:
        file_ext = ".wav"
    
    temp_filename = f"{uuid.uuid4()}{file_ext}"
    temp_path = UPLOAD_DIR / temp_filename
    
    with open(temp_path, "wb") as buffer:
        shutil.copyfileobj(upload_file.file, buffer)
    
    return str(temp_path)


def cleanup_file(file_path: str):
    """ì„ì‹œ íŒŒì¼ ì‚­ì œ"""
    try:
        if os.path.exists(file_path):
            os.remove(file_path)
    except Exception as e:
        print(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")


def parse_transcript_segments(transcript_path: str) -> List:
    """ì „ì‚¬ íŒŒì¼ì—ì„œ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ"""
    from .models import AudioSegment
    
    segments = []
    
    try:
        if not os.path.exists(transcript_path):
            return segments
        
        with open(transcript_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # í˜•ì‹: [mm:ss - mm:ss] í™”ìX: í…ìŠ¤íŠ¸
            pattern = r'\[(\d+):(\d+\.\d+)\s*-\s*(\d+):(\d+\.\d+)\]\s*(Speaker\d+|í™”ì\d+):\s*(.+)'
            match = re.match(pattern, line)
            
            if match:
                start_min, start_sec, end_min, end_sec, speaker, text = match.groups()
                start = int(start_min) * 60 + float(start_sec)
                end = int(end_min) * 60 + float(end_sec)
                
                segments.append(AudioSegment(
                    start=start,
                    end=end,
                    text=text.strip(),
                    speaker=speaker
                ))
    
    except Exception as e:
        print(f"ì„¸ê·¸ë¨¼íŠ¸ íŒŒì‹± ì‹¤íŒ¨: {e}")
    
    return segments


# ===== 1. ì˜¤ë””ì˜¤ íŒŒì´í”„ë¼ì¸ =====

@router.post("/audio/process", response_model=AudioProcessResponse)
async def process_audio(
    audio_file: UploadFile = File(..., description="ìŒì„± íŒŒì¼"),
    enable_denoise: bool = Form(True, description="ë…¸ì´ì¦ˆ ì œê±° í™œì„±í™”"),
    enable_transcription: bool = Form(True, description="STT í™œì„±í™”"),
    enable_diarization: bool = Form(True, description="í™”ìë¶„ë¦¬ í™œì„±í™”"),
    language: Optional[str] = Form(None, description="ì–¸ì–´ ì½”ë“œ (None=ìë™ê°ì§€)"),
    create_srt: bool = Form(True, description="SRT ìë§‰ íŒŒì¼ ìƒì„±"),
    save_outputs: bool = Form(True, description="ê²°ê³¼ íŒŒì¼ ì €ì¥")
):
    """
    ğŸµ í†µí•© ì˜¤ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    
    **ê¸°ëŠ¥:**
    1. ğŸ”‡ ë…¸ì´ì¦ˆ ì œê±° (SpeechBrain)
    2. ğŸ¤ STT (Whisper)
    3. ğŸ‘¥ í™”ì ë¶„ë¦¬
    4. ğŸ“ ìë§‰ ìƒì„± (SRT)
    
    **ì˜µì…˜:**
    - enable_denoise: ë…¸ì´ì¦ˆ ì œê±°ë§Œ ì›í•˜ë©´ transcription=false
    - enable_transcription: STTë§Œ ì›í•˜ë©´ denoise=false
    - enable_diarization: í™”ìë¶„ë¦¬ ì œì™¸í•˜ë ¤ë©´ false
    """
    from api import audio_pipeline
    
    pipeline = audio_pipeline.audio_pipeline_instance
    if pipeline is None:
        raise HTTPException(
            status_code=503,
            detail="ì˜¤ë””ì˜¤ íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        )
    
    temp_path = None
    total_start = time.time()
    timing = {}
    
    result = {
        "original_filename": audio_file.filename,
        "denoised": enable_denoise,
        "transcribed": enable_transcription,
        "diarization_enabled": enable_diarization,
    }
    
    try:
        temp_path = save_upload_file(audio_file)
        print(f"\n{'='*60}")
        print(f"ğŸ“ íŒŒì¼ ì—…ë¡œë“œ: {audio_file.filename}")
        print(f"{'='*60}\n")
        
        work_dir = UPLOAD_DIR / f"work_{uuid.uuid4().hex[:8]}"
        work_dir.mkdir(exist_ok=True)
        
        current_file = temp_path
        
        # 1. ë…¸ì´ì¦ˆ ì œê±°
        if enable_denoise:
            print("ğŸ”‡ ë…¸ì´ì¦ˆ ì œê±° ì‹œì‘...")
            denoise_start = time.time()
            
            denoised_file = work_dir / f"{Path(audio_file.filename).stem}_denoised.wav"
            
            pipeline.denoise_audio(
                input_file=current_file,
                output_file=str(denoised_file)
            )
            
            timing["denoise"] = time.time() - denoise_start
            result["denoised_filename"] = denoised_file.name
            result["denoise_time"] = round(timing["denoise"], 2)
            
            print(f"âœ… ë…¸ì´ì¦ˆ ì œê±° ì™„ë£Œ ({timing['denoise']:.2f}ì´ˆ)\n")
            
            current_file = str(denoised_file)
        else:
            print("â­ï¸  ë…¸ì´ì¦ˆ ì œê±° ìŠ¤í‚µ\n")
            result["denoised_filename"] = None
            result["denoise_time"] = None
        
        # 2. STT + í™”ìë¶„ë¦¬
        if enable_transcription:
            print("ğŸ¤ ìŒì„± ì „ì‚¬ ì‹œì‘...")
            transcription_start = time.time()
            
            transcript_result = pipeline.transcribe_uploaded_wav(
                wav_path=current_file,
                save_dir=str(work_dir) if save_outputs else None,
                create_srt=create_srt
            )
            
            timing["transcription"] = time.time() - transcription_start
            
            result["text"] = transcript_result["text"]
            result["detected_language"] = language or "auto"
            result["transcription_time"] = round(timing["transcription"], 2)
            
            print(f"âœ… ì „ì‚¬ ì™„ë£Œ ({timing['transcription']:.2f}ì´ˆ)\n")
            
            if save_outputs:
                result["transcript_path"] = transcript_result.get("transcript_path")
                result["simple_transcript_path"] = transcript_result.get("simple_path")
                result["text_only_path"] = transcript_result.get("text_only_path")
                result["srt_path"] = transcript_result.get("srt_path") if create_srt else None
                
                if result["transcript_path"]:
                    segments = parse_transcript_segments(result["transcript_path"])
                    result["segments"] = segments
                    result["num_speakers"] = len(set(s.speaker for s in segments if s.speaker))
            
        else:
            print("â­ï¸  ìŒì„± ì „ì‚¬ ìŠ¤í‚µ\n")
            result["text"] = None
            result["detected_language"] = None
            result["transcription_time"] = None
            result["num_speakers"] = None
            result["segments"] = None
        
        total_time = time.time() - total_start
        timing["total"] = total_time
        
        result["processing_time"] = round(total_time, 2)
        result["timing"] = {k: round(v, 2) for k, v in timing.items()}
        
        print("="*60)
        print(f"ğŸ‰ ì²˜ë¦¬ ì™„ë£Œ! ({total_time:.2f}ì´ˆ)")
        print("="*60 + "\n")
        
        return AudioProcessResponse(**result)
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {str(e)}\n")
        raise HTTPException(status_code=500, detail=str(e))
    
    finally:
        if temp_path:
            cleanup_file(temp_path)


# ===== 2. í…ìŠ¤íŠ¸ ë²ˆì—­ =====

@router.post("/translate-text", response_model=TranslationResponse)
async def translate_text_only(
    text: str = Form(..., description="ë²ˆì—­í•  í…ìŠ¤íŠ¸"),
    source_lang: str = Form("ko", description="ì›ë³¸ ì–¸ì–´ (ko, ja, en)"),
    target_lang: str = Form("ja", description="ëª©í‘œ ì–¸ì–´ (ko, ja, en)")
):
    """
    ğŸ“ í…ìŠ¤íŠ¸ ë²ˆì—­
    
    **ì§€ì› ì–¸ì–´:** ko â†” ja (ì–‘ë°©í–¥)
    """
    from api import translation
    
    start_time = time.time()
    
    try:
        print(f"ğŸŒ í…ìŠ¤íŠ¸ ë²ˆì—­: {source_lang} â†’ {target_lang}")
        print(f"   ì›ë¬¸: {text[:100]}...")
        
        result = translation.qwen3_translator.translate(
            text=text,
            source_lang=source_lang,
            target_lang=target_lang
        )
        
        processing_time = time.time() - start_time
        print(f"âœ… ë²ˆì—­ ì™„ë£Œ ({processing_time:.2f}ì´ˆ)")
        
        return TranslationResponse(
            original_text=text,
            translated_text=result["translated_text"],
            source_lang=source_lang,
            target_lang=target_lang,
            audio_filename="N/A",
            processing_time=round(processing_time, 2)
        )
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# ===== í—¬ìŠ¤ ì²´í¬ =====

@router.get("/health", response_model=BasicHealthResponse)
async def health_check():
    """ê¸°ë³¸ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    from api import inference
    from api import translation
    
    stt_ok = False
    stt_dev = "unknown"
    if hasattr(inference, 'whisper_stt') and inference.whisper_stt is not None:
        if hasattr(inference.whisper_stt, 'model') and inference.whisper_stt.model is not None:
            stt_ok = True
            stt_dev = getattr(inference.whisper_stt, 'device', 'unknown')
    
    trans_ok = False
    trans_dev = "unknown"
    if hasattr(translation, 'qwen3_translator') and translation.qwen3_translator is not None:
        if hasattr(translation.qwen3_translator, 'model') and translation.qwen3_translator.model is not None:
            trans_ok = True
            trans_dev = getattr(translation.qwen3_translator, 'device', 'unknown')
    
    return BasicHealthResponse(
        status="healthy",
        stt_loaded=stt_ok,
        translator_loaded=trans_ok,
        stt_device=stt_dev,
        translator_device=trans_dev
    )


@router.get("/audio/health", response_model=AudioHealthResponse)
async def audio_health():
    """ì˜¤ë””ì˜¤ íŒŒì´í”„ë¼ì¸ ìƒíƒœ í™•ì¸"""
    from api import audio_pipeline
    
    status = audio_pipeline.get_pipeline_status()
    
    return AudioHealthResponse(
        status="healthy" if status.get("initialized") else "not_initialized",
        initialized=status.get("initialized", False),
        device=status.get("device", "unknown"),
        models=status.get("models", {}),
        gpu_memory=status.get("gpu_memory")
    )


@router.get("/audio/memory")
async def memory_stats():
    """GPU ë©”ëª¨ë¦¬ ìƒíƒœ"""
    from api import audio_pipeline
    return audio_pipeline.get_memory_stats()


@router.get("/languages")
async def get_supported_languages():
    """ì§€ì› ì–¸ì–´ ëª©ë¡"""
    return {
        "stt": {
            "provider": "Whisper",
            "languages": "99ê°œ ì–¸ì–´ ì§€ì›"
        },
        "translation": {
            "provider": "Qwen3-8b LoRA",
            "languages": {
                "ko": "í•œêµ­ì–´",
                "ja": "æ—¥æœ¬èª",
                "en": "English"
            }
        }
    }