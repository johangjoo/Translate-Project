# transcribe_diarize_with_cleanup.py
import os, argparse, pathlib
from pathlib import Path
import torch, whisperx
from whisperx.diarize import DiarizationPipeline
import huggingface_hub
import gc
import psutil
import time

huggingface_hub.login("hf_")

# Windows ì „ìš©: PyTorch DLL ê²½ë¡œ ìš°ì„ 
try:
    os.add_dll_directory(str(pathlib.Path(torch.__file__).parents[1] / "lib"))
except Exception:
    pass

# ì˜µì…˜: ì†ë„ í–¥ìƒ(TF32). í•„ìš” ì—†ìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬.
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True

class WhisperXProcessor:
    """WhisperX ì²˜ë¦¬ê¸° - ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ì´ˆê¸°í™” ê¸°ëŠ¥ í¬í•¨"""
    
    def __init__(self, whisper_model="large-v3", device="cpu", compute_type="int8", hf_token=None):
        self.whisper_model = whisper_model
        self.device = device
        self.compute_type = compute_type
        self.hf_token = hf_token
        
        # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë“¤
        self.model = None
        self.align_model = None
        self.align_meta = None
        self.diar_pipe = None
        self.current_language = None
        
        # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
        self.process = psutil.Process()
        self.initial_memory = self.get_memory_usage()
        
        print(f"ğŸš€ WhisperX í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”")
        print(f"   - ëª¨ë¸: {whisper_model}")
        print(f"   - ë””ë°”ì´ìŠ¤: {device}")
        print(f"   - ì •ë°€ë„: {compute_type}")
        print(f"   - ì´ˆê¸° ë©”ëª¨ë¦¬: {self.initial_memory:.1f} MB")
    
    def get_memory_usage(self):
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë°˜í™˜ (MB)"""
        return self.process.memory_info().rss / 1024 / 1024
    
    def get_gpu_memory_usage(self):
        """GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë°˜í™˜ (MB)"""
        if torch.cuda.is_available():
            return torch.cuda.memory_allocated() / 1024 / 1024
        return 0
    
    def cleanup_models(self):
        """ëª¨ë“  ëª¨ë¸ê³¼ ìºì‹œ ì •ë¦¬"""
        print("ğŸ§¹ ëª¨ë¸ ì •ë¦¬ ì¤‘...")
        
        # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ
        if self.model is not None:
            del self.model
            self.model = None
        
        if self.align_model is not None:
            del self.align_model
            self.align_model = None
            
        if self.align_meta is not None:
            del self.align_meta
            self.align_meta = None
        
        if self.diar_pipe is not None:
            del self.diar_pipe
            self.diar_pipe = None
        
        self.current_language = None
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        gc.collect()
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥
        current_memory = self.get_memory_usage()
        gpu_memory = self.get_gpu_memory_usage()
        print(f"   - í˜„ì¬ ë©”ëª¨ë¦¬: {current_memory:.1f} MB")
        if torch.cuda.is_available():
            print(f"   - GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f} MB")
    
    def load_whisper_model(self):
        """Whisper ëª¨ë¸ ë¡œë“œ"""
        if self.model is None:
            print(f"ğŸ“¥ Whisper ëª¨ë¸ ë¡œë“œ: {self.whisper_model}")
            try:
                self.model = whisperx.load_model(
                    self.whisper_model, 
                    device=self.device, 
                    compute_type=self.compute_type
                )
            except Exception as e:
                print(f"âš ï¸  ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì¬ì‹œë„: {e}")
                self.model = whisperx.load_model(
                    self.whisper_model, 
                    device="cpu", 
                    compute_type="int8"
                )
    
    def load_align_model(self, language_code):
        """ì •ë ¬ ëª¨ë¸ ë¡œë“œ (ì–¸ì–´ë³„ ìºì‹±)"""
        if self.current_language != language_code or self.align_model is None:
            print(f"ğŸ“¥ ì •ë ¬ ëª¨ë¸ ë¡œë“œ: {language_code}")
            
            # ê¸°ì¡´ ì •ë ¬ ëª¨ë¸ ì •ë¦¬
            if self.align_model is not None:
                del self.align_model
                del self.align_meta
                gc.collect()
            
            self.align_model, self.align_meta = whisperx.load_align_model(
                language_code=language_code, 
                device=self.device
            )
            self.current_language = language_code
    
    def load_diarization_pipeline(self):
        """í™”ì ë¶„ë¦¬ íŒŒì´í”„ë¼ì¸ ë¡œë“œ"""
        if self.diar_pipe is None:
            print("ğŸ“¥ í™”ì ë¶„ë¦¬ íŒŒì´í”„ë¼ì¸ ë¡œë“œ")
            try:
                self.diar_pipe = DiarizationPipeline(
                    use_auth_token=self.hf_token, 
                    device=self.device
                )
            except OSError as e:
                print(f"âš ï¸  GPU í™”ìë¶„ë¦¬ ì‹¤íŒ¨, CPUë¡œ í´ë°±: {e}")
                self.diar_pipe = DiarizationPipeline(
                    use_auth_token=self.hf_token, 
                    device="cpu"
                )
    
    def process_single_file(self, audio_path, output_dir, batch_size=8, 
                          min_speakers=None, max_speakers=None):
        """ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬"""
        audio_path = Path(audio_path)
        output_dir = Path(output_dir)
        
        print(f"\nğŸµ ì²˜ë¦¬ ì¤‘: {audio_path.name}")
        start_time = time.time()
        
        try:
            # 1. ì˜¤ë””ì˜¤ ë¡œë“œ
            audio = whisperx.load_audio(str(audio_path))
            
            # 2. Whisper ëª¨ë¸ ë¡œë“œ ë° ì „ì‚¬
            self.load_whisper_model()
            
            try:
                result = self.model.transcribe(audio, batch_size=batch_size)
            except RuntimeError as e:
                # cuBLAS ì˜¤ë¥˜ ì²˜ë¦¬
                if "cublas" in str(e).lower() and "int8" in self.compute_type:
                    print("âš ï¸  cuBLAS INT8 ì˜¤ë¥˜, FP16ìœ¼ë¡œ ì¬ì‹œë„")
                    self.cleanup_models()
                    self.compute_type = "float16"
                    self.load_whisper_model()
                    result = self.model.transcribe(audio, batch_size=batch_size)
                else:
                    raise
            
            language = result.get("language", "ko")
            print(f"   - ê°ì§€ëœ ì–¸ì–´: {language}")
            
            # 3. ì •ë ¬ ëª¨ë¸ ë¡œë“œ ë° ì •ë ¬
            self.load_align_model(language)
            aligned_result = whisperx.align(
                result["segments"], 
                self.align_model, 
                self.align_meta, 
                audio, 
                self.device, 
                return_char_alignments=False
            )
            
            # 4. í™”ì ë¶„ë¦¬
            self.load_diarization_pipeline()
            
            diar_kwargs = {}
            if min_speakers is not None:
                diar_kwargs["min_speakers"] = min_speakers
            if max_speakers is not None:
                diar_kwargs["max_speakers"] = max_speakers
            
            diarization_result = self.diar_pipe(audio, **diar_kwargs)
            final_result = whisperx.assign_word_speakers(diarization_result, aligned_result)
            
            # 5. ê²°ê³¼ ì €ì¥
            output_path = self.save_transcript(final_result, audio_path, output_dir, language)
            
            # 6. ì²˜ë¦¬ ì™„ë£Œ ì •ë³´
            elapsed_time = time.time() - start_time
            current_memory = self.get_memory_usage()
            print(f"âœ… ì™„ë£Œ: {audio_path.name}")
            print(f"   - ì¶œë ¥: {output_path.name}")
            print(f"   - ì²˜ë¦¬ ì‹œê°„: {elapsed_time:.1f}ì´ˆ")
            print(f"   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {current_memory:.1f} MB")
            
            return output_path
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {audio_path.name} - {e}")
            return None
        
        finally:
            # ì˜¤ë””ì˜¤ ë©”ëª¨ë¦¬ ì •ë¦¬
            if 'audio' in locals():
                del audio
            gc.collect()
    
    def save_transcript(self, result, audio_path, output_dir, language):
        """ì „ì‚¬ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # í™”ì ë§¤í•‘ ë° ë¼ì¸ ìƒì„±
        speaker_map = {}
        lines = []
        
        for segment in sorted(result["segments"], key=lambda x: x.get("start", 0.0)):
            text = (segment.get("text") or "").strip()
            if not text:
                continue
            
            speaker = segment.get("speaker", "UNK")
            if speaker not in speaker_map:
                speaker_map[speaker] = f"í™”ì{len(speaker_map) + 1}"
            
            start_time = segment.get("start", 0.0)
            time_str = self.format_time(start_time)
            lines.append(f"[{time_str}] {speaker_map[speaker]} : {text}")
        
        # íŒŒì¼ ì €ì¥
        output_path = output_dir / f"{audio_path.stem}_transcript_{language}.txt"
        with output_path.open("w", encoding="utf-8") as f:
            for line in lines:
                f.write(line + "\n")
        
        return output_path
    
    def format_time(self, seconds):
        """ì‹œê°„ì„ MM:SS í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if not isinstance(seconds, (int, float)) or seconds != seconds or seconds < 0:
            seconds = 0.0
        
        minutes = int(seconds // 60)
        secs = int(round(seconds - minutes * 60))
        
        if secs == 60:
            minutes += 1
            secs = 0
        
        return f"{minutes:02d}:{secs:02d}"
    
    def process_batch(self, input_path, output_dir, batch_size=8, 
                     min_speakers=None, max_speakers=None, 
                     file_pattern="*.mp4", cleanup_interval=5):
        """ë°°ì¹˜ ì²˜ë¦¬ - ì—¬ëŸ¬ íŒŒì¼ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬"""
        input_path = Path(input_path)
        output_dir = Path(output_dir)
        
        # íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
        if input_path.is_file():
            files = [input_path]
        else:
            # ì—¬ëŸ¬ ì˜¤ë””ì˜¤ í˜•ì‹ ì§€ì›
            audio_extensions = ["*.mp4", "*.wav", "*.mp3", "*.flac", "*.m4a", "*.aac", "*.ogg"]
            files = []
            
            if file_pattern != "*.mp4":
                files = sorted(input_path.glob(file_pattern))
            else:
                for ext in audio_extensions:
                    files.extend(input_path.glob(ext))
                files = sorted(set(files))
        
        if not files:
            print(f"âŒ {input_path}ì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ“ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(files)}ê°œ íŒŒì¼")
        for i, file_path in enumerate(files, 1):
            print(f"  {i}. {file_path.name}")
        
        # íŒŒì¼ë³„ ì²˜ë¦¬
        successful = 0
        failed = 0
        
        for i, file_path in enumerate(files, 1):
            print(f"\n{'='*60}")
            print(f"ğŸ“Š ì§„í–‰ë¥ : {i}/{len(files)} ({i/len(files)*100:.1f}%)")
            
            result = self.process_single_file(
                file_path, output_dir, batch_size, min_speakers, max_speakers
            )
            
            if result:
                successful += 1
            else:
                failed += 1
            
            # ì£¼ê¸°ì ìœ¼ë¡œ ëª¨ë¸ ì •ë¦¬ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
            if i % cleanup_interval == 0 or i == len(files):
                print(f"\nğŸ”„ ì£¼ê¸°ì  ì •ë¦¬ ({i}/{len(files)})")
                self.cleanup_models()
                
                # ì ì‹œ ëŒ€ê¸° (ì‹œìŠ¤í…œ ì•ˆì •í™”)
                time.sleep(2)
        
        # ìµœì¢… ê²°ê³¼
        print(f"\n{'='*60}")
        print(f"ğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"   - ì„±ê³µ: {successful}ê°œ")
        print(f"   - ì‹¤íŒ¨: {failed}ê°œ")
        print(f"   - ì´ ì²˜ë¦¬: {len(files)}ê°œ")
        
        # ìµœì¢… ì •ë¦¬
        self.cleanup_models()

def main():
    ap = argparse.ArgumentParser(
        description="WhisperX ë°°ì¹˜ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ì´ˆê¸°í™” ê¸°ëŠ¥ í¬í•¨)",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    ap.add_argument("--src", default="video_input", help="ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŒŒì¼ ë˜ëŠ” í´ë”")
    ap.add_argument("--out_dir", default="input", help="ì¶œë ¥ í´ë”")
    ap.add_argument("--whisper_model", default="large-v3", help="Whisper ëª¨ë¸ëª…")
    ap.add_argument("--batch_size", type=int, default=8, help="ë°°ì¹˜ í¬ê¸°")
    ap.add_argument("--min_speakers", type=int, default=None, help="ìµœì†Œ í™”ì ìˆ˜")
    ap.add_argument("--max_speakers", type=int, default=None, help="ìµœëŒ€ í™”ì ìˆ˜")
    ap.add_argument("--hf_token", default=None, help="Hugging Face í† í°")
    ap.add_argument("--force_cpu", action="store_true", help="CPU ê°•ì œ ì‚¬ìš©")
    ap.add_argument("--compute_type", default=None, help="ì—°ì‚° ì •ë°€ë„")
    ap.add_argument("--ext", default="*.mp4", help="íŒŒì¼ í™•ì¥ì íŒ¨í„´")
    ap.add_argument("--cleanup_interval", type=int, default=5, help="ì •ë¦¬ ì£¼ê¸° (íŒŒì¼ ê°œìˆ˜)")
    
    args = ap.parse_args()
    
    # í† í° ì„¤ì •
    token = (
        args.hf_token
        or os.getenv("HUGGINGFACE_HUB_TOKEN")
        or os.getenv("HUGGINGFACE_TOKEN")
        or os.getenv("HF_TOKEN")
    )
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = "cpu" if args.force_cpu else ("cuda" if torch.cuda.is_available() else "cpu")
    
    # ì •ë°€ë„ ì„¤ì •
    if args.compute_type:
        compute_type = args.compute_type
    else:
        compute_type = "float16" if device == "cuda" else "int8"
    
    # í”„ë¡œì„¸ì„œ ìƒì„± ë° ì‹¤í–‰
    processor = WhisperXProcessor(
        whisper_model=args.whisper_model,
        device=device,
        compute_type=compute_type,
        hf_token=token
    )
    
    try:
        processor.process_batch(
            input_path=args.src,
            output_dir=args.out_dir,
            batch_size=args.batch_size,
            min_speakers=args.min_speakers,
            max_speakers=args.max_speakers,
            file_pattern=args.ext,
            cleanup_interval=args.cleanup_interval
        )
    except KeyboardInterrupt:
        print("\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\nâŒ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
    finally:
        print("\nğŸ§¹ ìµœì¢… ì •ë¦¬...")
        processor.cleanup_models()

if __name__ == "__main__":
    main()
